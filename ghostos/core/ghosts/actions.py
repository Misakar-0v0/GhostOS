from typing import Optional, ClassVar, Type, TypeVar, Generic
import json
from abc import ABC, abstractmethod
from ghostos.container import Container
from ghostos.core.llms import Prompt, LLMFunc, PromptPipe
from ghostos.core.ghosts.operators import Operator
from ghostos.core.messages.message import Caller
from ghostos.core.runtime import Session
from ghostos.common import Identical, Identifier
from pydantic import BaseModel

__all__ = ['Action', 'ToolAction']


class Action(Identical, PromptPipe, ABC):
    """
    ghost actions that triggered by LLM output's caller
    """

    @abstractmethod
    def process(self, chat: Prompt) -> Prompt:
        """
        Action update the chat with messages, tool, functional_tokens, etc.
        :param chat: origin chat.
        :return: updated chat. may be a copy.
        """
        pass

    @abstractmethod
    def act(self, container: "Container", session: Session, caller: Caller) -> Optional["Operator"]:
        """
        took an action with ghost generated caller
        :param container: container may be changed comparing to when the action is created. so pass the new one.
        :param session: the session
        :param caller: the caller generated by the ghost runner (usually driven by llm)
        :return: the operator that predefined to control the ghost state
        """
        pass


A = TypeVar('A', bound=Type[BaseModel])


class ToolAction(Action, Generic[A], ABC):
    """
    定义一个 ToolAction.
    泛型并不是必须的, 主要是提示 ToolAction 如何生成.
    """
    name: ClassVar[str]
    """工具的名字"""

    description: ClassVar[str]
    """工具的描述"""

    args_model: A
    """工具的入参. """

    @abstractmethod
    def do_act(self, container: "Container", session: Session, arguments: A) -> Optional["Operator"]:
        """
        工具真实的实现.
        """
        pass

    def process(self, chat: Prompt) -> Prompt:
        """
        将工具注入到 chat.
        """
        tool = LLMFunc.new(
            name=self.name,
            desc=self.description,
            parameters=self.args_model.model_json_schema(),
        )
        chat.functions.append(tool)
        return chat

    def act(self, container: "Container", session: Session, caller: Caller) -> Optional["Operator"]:
        """
        接受 LLM 生产的 caller 运行.
        """
        # 反解出 json
        loaded = json.loads(caller.arguments)
        # 反解出 ToolActionArgs
        arguments = self.args_model(**loaded)
        # 运行逻辑.
        return self.act(container, session, arguments)

    def identifier(self) -> Identifier:
        """
        对自身的描述.
        """
        return Identifier(
            name=self.name,
            description=self.description,
        )
